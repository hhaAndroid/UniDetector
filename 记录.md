# 环境构建

conda create -n unidet python=3.8 -y
conda activate unidet
pip install torch==1.9.1+cu111 torchvision==0.10.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html

pip install -U openmim
mim install "mmcv-full<1.4.0" # 1.3.18
pip install -r requirements/runtime.txt
pip install -e .

# Demo
去官方地址 google drive 下载模型文件，放到 `./checkpoints/` 下

仅在 coco 上面训练，然后在 lvis0.5 上面进行测试，效果很差，如下所示

```bash
python demo/image_demo.py demo/demo.jpg configs/inference/clip_end2end_faster_rcnn_r50_c4_1x_lvis_v0.5.py checkpoints/epoch_12_end2end_coco.pth --palette lvis5
```

在 coco 上面训练，在 coco 上面测试，效果也一般，效果如下：

```bash
python demo/image_demo.py demo/demo.jpg configs/singledataset/clip_end2end_faster_rcnn_r50_c4_1x_coco.py checkpoints/epoch_12_end2end_coco.pth 
```

# 准备数据

```text
data/lvis_v0.5/
        train2017/
        val2017/
        annotations/
            lvis_v0.5_train.json
            lvis_v0.5_val.json
```

```shell
python tools/test.py configs/inference/clip_end2end_faster_rcnn_r50_c4_1x_lvis_v0.5.py checkpoints/epoch_12_end2end_coco.pth --eval bbox

bash tools/dist_test.sh configs/inference/clip_end2end_faster_rcnn_r50_c4_1x_lvis_v0.5.py checkpoints/epoch_12_end2end_coco.pth 8 --eval bbox
```

## clip_end2end_faster_rcnn_r50_c4_1x_coco.py 分析

